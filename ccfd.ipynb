{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA536M1xVELeDrvBTIm3cD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farzadmohseni-ir/credit-card-fraud-detection/blob/main/ccfd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 🏷️ **Topic: Credit Card Fraud Detection (CCFD)**\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "### 🏷️ **موضوع: کشف تقلب در کارت‌های اعتباری**\n",
        "\n",
        "---\n",
        "\n",
        "### 📌 **تعریف موضوع:**\n",
        "\n",
        "کشف تقلب در کارت‌های اعتباری یکی از مسائل مهم در حوزه‌ی علم داده و امنیت مالی است. با گسترش استفاده از پرداخت‌های دیجیتال و تراکنش‌های آنلاین، شناسایی سریع و دقیق فعالیت‌های متقلبانه برای بانک‌ها، شرکت‌های پرداخت و نهادهای مالی ضروری است.\n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 **اهداف تحقیق:**\n",
        "\n",
        "1. طراحی و توسعه یک سامانهٔ هوشمند به‌منظور افزایش دقت در شناسایی تراکنش‌های تقلبی.  \n",
        "2. کاهش نرخ تشخیص نادرست تراکنش‌های سالم به‌ ‌عنوان تقلب (کاهش مثبت‌های کاذب).  \n",
        "3. افزایش نرخ شناسایی صحیح تراکنش‌های تقلبی به‌ منظور ارتقاء امنیت سامانه‌های پرداخت.  \n",
        "4. جلوگیری از آسیب به اعتبار مؤسسات مالی در اثر تصمیمات نادرست سیستم‌های تشخیص تقلب.  \n",
        "5. حفظ  رضایت و اعتماد مشتریان با کاهش موارد رد نادرست تراکنش‌های معتبر.\n",
        "\n",
        "---\n",
        "\n",
        "### ⚠️ **چالش‌های اصلی:**\n",
        "\n",
        "- عدم توازن شدید بین کلاس‌های «تقلب» و «عدم تقلب» در داده‌ها.\n",
        "- وجود نویز و ویژگی‌های نامربوط در دیتاست.\n",
        "- دشواری در ارزیابی مدل‌ها به دلیل نرخ پایین وقوع تقلب (rare event).\n",
        "- ریسک بیش‌برازش (Overfitting) در مدل‌های پیچیده.\n",
        "- نیاز به پیاده‌سازی تکنیک‌های پیش‌پردازش و انتخاب ویژگی.\n"
      ],
      "metadata": {
        "id": "AyCQvCbQ2C7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### 📊 مقایسه سه دیتاست معروف مرتبط با کشف تقلب در کارت‌های اعتباری\n",
        "\n",
        "| ویژگی | دیتاست اول (ULB 2016) | دیتاست دوم (Nelgiriyewithana - 2023) | دیتاست سوم (IEEE-CIS 2019) |\n",
        "|:---|:---|:---|:---|\n",
        "| 🏷️ عنوان دیتاست | Credit Card Fraud Detection | Credit Card Fraud Detection Dataset 2023 | IEEE-CIS Fraud Detection |\n",
        "| 🌍 منبع | ULB (Université Libre de Bruxelles) | Kaggle (کاربر nelgiriyewithana) | IEEE-CIS / Vesta Corporation |\n",
        "| 📦 تعداد رکورد | 284,807 | 550,000 | 590,540 |\n",
        "| 🔢 تعداد ویژگی | 30 | 30 | 431 (400 عددی + 31 دسته‌ای) |\n",
        "| 🧩 نوع ویژگی‌ها | ناشناس‌شده با PCA (فقط V1-V28) | ناشناس‌شده (Amount, Category, etc.) | ویژگی‌های متنوع دستگاه، کارت، آدرس، ایمیل و ... |\n",
        "| 🔍 نرخ تقلب | 0.172٪ (492 مورد) | شدیداً نامتوازن (تعداد دقیق مشخص نیست) | 3.5٪ (20,663 مورد) |\n",
        "| 🎯 نوع برچسب هدف | 0 (عادی) و 1 (تقلب) | 0 (عادی) و 1 (تقلب) | 0 (عادی) و 1 (تقلب) |\n",
        "| ⚙️ کاربردپذیری برای تحقیق | بله (مرجع معتبر علمی) | بله، مناسب برای نوآوری | بله، بسیار مناسب برای رقابت و مدل‌های پیشرفته |\n",
        "| 📚 پیشنهاد شده برای | مقایسه مدل‌ها (Benchmark) | نوآوری در مدل‌ها و ویژگی‌سازی | یادگیری عمیق، مهندسی ویژگی، AutoML و ... |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1PT-iQM25A_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "### 🧠 جدول مراحل آماده‌ سازی داده و مدل سازی  \n",
        "\n",
        "| 🔢 ردیف | مرحله | عنوان انگلیسی | شرح مختصر |\n",
        "|--------|--------|----------------|------------|\n",
        "| 1 | جمع‌آوری داده | Data Collection | دریافت داده‌ها از منابع معتبر مانند دیتاست‌های عمومی یا پایگاه‌های سازمانی |\n",
        "| 2 | درک داده | Data Understanding | تحلیل اولیه برای شناخت ساختار، انواع ویژگی‌ها و برچسب‌ها |\n",
        "| 3 | پاک‌سازی داده | Data Cleaning | اصلاح داده‌های گمشده، حذف داده‌های پرت، و رفع ناسازگاری‌ها |\n",
        "| 4 | پیش‌پردازش داده | Data Preprocessing | نرمال‌سازی، کدگذاری داده‌های دسته‌ای، و آماده‌سازی ویژگی‌ها |\n",
        "| 5 | متعادل‌سازی داده | Data Balancing | رفع مشکل نامتوازنی کلاس‌ها  |\n",
        "| 6 | تحلیل اکتشافی | Exploratory Data Analysis (EDA) | بررسی آماری ویژگی‌ها، رسم نمودارها و بررسی توزیع داده‌ها |\n",
        "| 7 | مهندسی ویژگی | Feature Engineering | ساخت ویژگی‌های جدید یا تبدیل ویژگی‌های موجود برای بهبود مدل |\n",
        "| 8 | انتخاب ویژگی | Feature Selection | حذف ویژگی‌های کم‌اثر و انتخاب ویژگی‌های کلیدی با تکنیک‌های آماری |\n",
        "| 9 | تقسیم‌بندی داده | Train-Test Split | جداسازی داده به مجموعه آموزش و آزمون برای ارزیابی مدل |\n",
        "| 10 | مدل‌سازی | Modeling | آموزش مدل با الگوریتم‌های مناسب و تنظیم پارامترها |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "tYuWv72a615O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### ⚖️ جدول نهایی روش‌های متعادل‌سازی داده (با مزایا، معایب، توضیح عملکرد و تناسب با دیتاست)\n",
        "\n",
        "| 🔢 ردیف | عنوان روش | نوع | مزایا | معایب | مناسب برای دیتاست من؟ |\n",
        "|--------|------------|------|--------|--------|-------------------------|\n",
        "| 1 | Random Undersampling | Undersampling | ساده و سریع، کاهش حجم داده | احتمال حذف اطلاعات مفید | ❌ خیلی ضعیف برای دیتاست بزرگ و نامتوازن |\n",
        "|   |  |  |  ➤ با حذف تصادفی از کلاس غالب، کلاس‌ها را برابر می‌کند. |  |  |\n",
        "| 2 | Random Oversampling | Oversampling | حفظ داده‌ها، اجرای آسان | احتمال بیش‌برازش | ⚠️ فقط برای تست‌های اولیه یا مدل‌های ساده پیشنهاد می‌شود |\n",
        "|   |  |  |  ➤ با تکرار تصادفی نمونه‌های کلاس اقلیت، تعادل ایجاد می‌کند. |  |  |\n",
        "| 3 | SMOTE | Oversampling | تولید داده‌های متنوع، کاهش Overfitting | ممکن است داده مصنوعی نامعتبر تولید کند | ✅ مناسب، مخصوصاً برای شروع مدل‌سازی و مقایسه |\n",
        "|   |  |  |  ➤ داده‌های مصنوعی بین نزدیک‌ترین همسایه‌ها تولید می‌کند. |  |  |\n",
        "| 4 | Borderline-SMOTE | Oversampling | تمرکز بر نقاط بحرانی، افزایش دقت | حساس به نویز | ✅ مناسب، به‌ویژه برای مدل‌های دقیق‌تر |\n",
        "|   |  |  |  ➤ فقط اطراف مرز کلاس‌ها نمونه‌سازی می‌کند. |  |  |\n",
        "| 5 | ADASYN | Oversampling | تطبیق‌پذیر، تنوع بالا | ممکن است داده غیرواقعی تولید شود | ✅ مناسب برای مدل‌های پیچیده‌تر |\n",
        "|   |  |  |  ➤ در نواحی سخت‌تر، داده بیشتری تولید می‌کند. |  |  |\n",
        "| 6 | SMOTE-ENN | Hybrid | حذف نویز، داده تمیزتر | پیچیده‌تر و زمان‌بر | ✅ بسیار مناسب، مخصوصاً اگر دقت مهم باشد |\n",
        "|   |  |  |  ➤ پس از SMOTE، نمونه‌های نویزی را با ENN حذف می‌کند. |  |  |\n",
        "| 7 | SMOTE-Tomek | Hybrid | حذف همپوشانی کلاس‌ها | پردازش بیشتر نیاز دارد | ✅ مناسب برای حذف داده‌های مبهم و مرزی |\n",
        "|   |  |  |  ➤ SMOTE + حذف نمونه‌های متداخل با Tomek Links |  |  |\n",
        "| 8 | KMeans-SMOTE | Oversampling هوشمند | متنوع، کاهش Overfitting | نیاز به تنظیم دقیق K | ✅✅ بسیار مناسب برای دیتاست بزرگ و واقعی تو |\n",
        "|   |  |  |  ➤ با خوشه‌بندی قبل از SMOTE، داده متعادل و متنوع‌تری تولید می‌کند. |  |  |\n",
        "\n",
        "📌 راهنمای علامت‌ها:\n",
        "- ✅ پیشنهاد می‌شود  \n",
        "- ✅✅ کاملاً توصیه می‌شود  \n",
        "- ⚠️ قابل استفاده ولی نه بهترین انتخاب  \n",
        "- ❌ مناسب نیست برای دیتاست تو  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ppw_uiGjBzEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### 📊 دسته‌بندی روش‌های مدل‌سازی در کشف تقلب کارت اعتباری (CCFD)\n",
        "\n",
        "| 🔢 ردیف | 🧠 دسته روش             | 🔤 عنوان انگلیسی               | 🧪 الگوریتم‌ها |\n",
        "|--------|--------------------------|--------------------------------|-----------------------------|\n",
        "| 1️⃣     | یادگیری ماشین      |  Machine Learning     | Decision Tree, Logistic Regression, SVM, Naive Bayes, KNN |\n",
        "| 2️⃣     | یادگیری انسمبل           | Ensemble Learning              | Random Forest, AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost |\n",
        "| 3️⃣     | یادگیری عمیق            | Deep Learning                  | MLP, CNN, RNN, LSTM, Autoencoder |\n",
        "| 4️⃣     | یادگیری ترکیبی          | Hybrid Learning                | ML + DL، Rule-Based + ML، Stacking، Blending |\n",
        "| 5️⃣     | مدل‌های گرافی            | Graph-Based Models             | GCN، GAT، GraphSAGE، Graph Attention Network، GATv2 |\n",
        "| 6️⃣     | کشف ناهنجاری            | Anomaly Detection              | Isolation Forest، One-Class SVM، LOF، Autoencoder (Unsupervised) |\n",
        "| 7️⃣     | یادگیری نیمه‌نظارتی       | Semi-Supervised Learning       | Label Propagation، Self-Training، Semi-Supervised SVM، Co-Training |\n",
        "| 8️⃣     | یادگیری تقویتی           | Reinforcement Learning         | Q-Learning، Deep Q-Network (DQN)، SARSA، Policy Gradient |\n",
        "| 9️⃣     | یادگیری بدون نظارت        | Unsupervised Learning          | KMeans، DBSCAN، PCA، Autoencoder (Unsupervised) |\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1VhaBgWbVHnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### ✳️ **بیان موضوعات پایان‌نامه بر اساس دسته‌بندی روش‌های مدل‌سازی در کشف تقلب کارت‌های اعتباری** 💳🧠📊\n",
        "\n",
        "### 1️⃣ یادگیری ماشین | Machine Learning  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از تکنیک‌های متعادل‌سازی داده و الگوریتم‌های یادگیری ماشین  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Data Balancing Techniques and Classical Machine Learning Algorithms\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ یادگیری انسمبل | Ensemble Learning  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های انسمبل و تکنیک‌های متعادل‌سازی داده  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Ensemble Models and Data Balancing Techniques\n",
        "\n",
        "---\n",
        "\n",
        "### 3️⃣ یادگیری عمیق | Deep Learning  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از الگوریتم‌های یادگیری عمیق و رویکردهای مقابله با عدم‌توازن داده  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Deep Learning Algorithms and Imbalanced Data Handling Approaches\n",
        "\n",
        "---\n",
        "\n",
        "### 4️⃣ یادگیری ترکیبی | Hybrid Learning  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های ترکیبی و تکنیک‌های متعادل‌سازی داده  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Hybrid Models and Data Balancing Techniques\n",
        "\n",
        "---\n",
        "\n",
        "### 5️⃣ مدل‌های گرافی | Graph-Based Models  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های مبتنی بر گراف و روش‌های مقابله با عدم‌توازن داده  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Graph-Based Models and Imbalanced Data Handling Techniques\n",
        "\n",
        "---\n",
        "\n",
        "### 6️⃣ کشف ناهنجاری | Anomaly Detection  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از روش‌های کشف ناهنجاری و تکنیک‌های متعادل‌سازی داده  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Anomaly Detection Methods and Data Balancing Techniques\n",
        "\n",
        "---\n",
        "\n",
        "### 7️⃣ یادگیری نیمه‌نظارتی | Semi-Supervised Learning  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از یادگیری نیمه‌نظارتی و روش‌های مدیریت داده‌های نامتوازن  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Semi-Supervised Learning and Imbalanced Data Handling Techniques\n",
        "\n",
        "---\n",
        "\n",
        "### 8️⃣ یادگیری تقویتی | Reinforcement Learning  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از یادگیری تقویتی و تکنیک‌های مقابله با داده‌های نامتوازن  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Reinforcement Learning and Imbalanced Data Handling Approaches\n",
        "\n",
        "---\n",
        "\n",
        "### 9️⃣ یادگیری بدون نظارت | Unsupervised Learning  \n",
        "\n",
        "📌 **فارسی:**  \n",
        "کشف تقلب در کارت‌های اعتباری با استفاده از الگوریتم‌های یادگیری بدون نظارت و تحلیل داده‌های نامتوازن  \n",
        "\n",
        "📘 **English:**  \n",
        "Credit Card Fraud Detection (CCFD) Using Unsupervised Learning Algorithms and Imbalanced Data Analysis\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "mY55rhh9Vt1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "و نتیجه نهایی این شد:\n",
        "\n",
        "### ✔️ **مسیر پیشنهادی نهایی برای پایان‌ نامه:**\n",
        "\n",
        "\n",
        "### 🧠 مدل‌های انسمبل چیستند؟  \n",
        "مدل‌های انسمبل مجموعه‌ای از الگوریتم‌های یادگیری ماشین هستند که به‌جای تکیه بر یک مدل واحد، چندین مدل پایه را ترکیب می‌کنند تا یک تصمیم نهایی دقیق‌تر، پایدارتر و قابل اعتمادتر ارائه دهند.  \n",
        "\n",
        "ایده اصلی انسمبل این است که «ترکیب چند مدل ضعیف، می‌تواند منجر به یک مدل قوی‌تر شود» – درست مانند خرد جمعی.\n",
        "\n",
        "---\n",
        "\n",
        "### 💡 مزایای کلیدی انسمبل:\n",
        "- **🎯 افزایش دقت:** با ترکیب چند مدل، خطاهای فردی کاهش می‌یابد.  \n",
        "- **🛡️ کاهش overfitting:** به‌ویژه در داده‌های نامتوازن مثل CCFD بسیار مؤثر است.  \n",
        "- **📊 پایداری بیشتر:** خروجی نهایی از چند زاویه بررسی می‌شود، نه فقط یک دیدگاه.  \n",
        "- **🧪 انعطاف‌پذیری:** می‌توان مدل‌ها را از خانواده‌های مختلف ترکیب کرد (مثلاً Tree و Boost).\n",
        "\n",
        "---\n",
        "\n",
        "### 🎯 مدل‌های انسمبل زیرمجموعه کدام دسته‌اند؟\n",
        "### ⛓️ ساختار سلسله‌مراتبی:\n",
        "\n",
        "</div>\n",
        "\n",
        "```\n",
        "هوش مصنوعی (AI)\n",
        "└── یادگیری ماشین (Machine Learning)\n",
        "    └── یادگیری نظارت‌شده (Supervised Learning)\n",
        "        └── مدل‌های انسمبل (Ensemble Models)\n",
        "```\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "---\n",
        "\n",
        "### ✳️ چرا برای پایان‌نامه ما مناسب است؟\n",
        "در مسئله کشف تقلب در کارت‌های اعتباری، داده‌ها به‌شدت نامتوازن و حساس‌اند. انسمبل‌ها با قدرت ترکیب و تعمیم، می‌توانند خطاهای تشخیص را کاهش داده، دقت را بالا برده و راهکاری قوی‌تر از مدل‌های ساده ارائه کنند.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "hhsud6vjbc-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "## 🎯 انواع مدل‌های انسمبل (Ensemble Models)\n",
        "\n",
        "\n",
        "### 1️⃣ **Bagging (Bootstrap Aggregating)**\n",
        "\n",
        "روش Bagging یکی از تکنیک‌های انسمبل ساده و مؤثر در یادگیری ماشین است که هدف اصلی آن **کاهش واریانس و افزایش پایداری مدل** است. در این روش:\n",
        "\n",
        "1. از دیتای اصلی، چندین **زیرمجموعه تصادفی با جایگزینی (Bootstrapped samples)** ساخته می‌شود.\n",
        "2. روی هر زیرمجموعه، **یک مدل مشابه از یک الگوریتم واحد** (مثلاً فقط درخت تصمیم) آموزش داده می‌شود.\n",
        "3. خروجی نهایی از طریق **رأی‌گیری اکثریت (برای طبقه‌بندی)** یا **میانگین‌گیری (برای رگرسیون)** به‌دست می‌آید.\n",
        "\n",
        "\n",
        "### ✅ ویژگی‌های کلیدی:\n",
        "- همه مدل‌ها از **یک الگوریتم مشخص** استفاده می‌کنند.  \n",
        "- تنها تفاوت بین آن‌ها، **نمونه‌های آموزش متفاوت** است.  \n",
        "- انتخاب داده‌ها در هر زیرمجموعه، کاملاً **تصادفی با جایگزینی** انجام می‌شود.  \n",
        "- مدل نهایی با ترکیب خروجی‌ها، به **نتیجه‌ای دقیق‌تر، پایدارتر و مقاوم‌تر در برابر نویز** می‌رسد.\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ **Boosting**\n",
        "\n",
        "روش Boosting یکی از تکنیک‌های قدرتمند انسمبل در یادگیری ماشین است که با هدف **کاهش بایاس و افزایش دقت مدل** طراحی شده است. در این روش:\n",
        "\n",
        "1. مدل‌های پایه (معمولاً ضعیف) به‌صورت **ترتیبی و زنجیره‌ای** آموزش داده می‌شوند.  \n",
        "2. هر مدل جدید، **روی خطاهای مدل قبلی تمرکز** می‌کند و تلاش می‌کند پیش‌بینی آن‌ها را اصلاح کند.  \n",
        "3. خروجی نهایی با **ترکیب وزن‌دار پیش‌بینی‌های تمام مدل‌ها** به‌دست می‌آید.\n",
        "\n",
        "\n",
        "### ✅ ویژگی‌های کلیدی:\n",
        "\n",
        "- همه مدل‌ها از **یک الگوریتم یکسان** (مثلاً درخت تصمیم ساده) استفاده می‌کنند.  \n",
        "- مدل‌ها به‌صورت **وابسته و مرحله‌ای** آموزش می‌بینند.  \n",
        "- در هر مرحله، به **نمونه‌های اشتباه‌شده قبلی وزن بیشتری** داده می‌شود.  \n",
        "- Boosting در مواجهه با **داده‌های نامتوازن و الگوهای پیچیده** عملکرد بسیار دقیقی دارد.\n",
        "\n",
        "---\n",
        "\n",
        "### 3️⃣ **Stacking (Stacked Generalization)**\n",
        "\n",
        "Stacking یک تکنیک انسمبل پیشرفته در یادگیری ماشین است که با هدف افزایش دقت مدل نهایی، از **ویژگی‌سازی مبتنی بر خروجی چند مدل مختلف** استفاده می‌کند و آن‌ها را به یک **مدل نهایی هوشمند** می‌سپارد تا تصمیم‌گیری نهایی انجام شود.\n",
        "\n",
        "1. چندین **مدل پایه (Base Learners)** با الگوریتم‌های متفاوت (مثل SVM، Random Forest، KNN) روی داده‌ی اصلی آموزش داده می‌شوند.  \n",
        "2. خروجی‌های این مدل‌ها (پیش‌بینی یا احتمال) برای هر نمونه استخراج می‌گردد.  \n",
        "3. این خروجی‌ها به‌عنوان **ویژگی‌های جدید** به یک **مدل نهایی (Meta Learner)** داده می‌شوند تا تصمیم نهایی را اتخاذ کند.\n",
        "\n",
        "### ✅ ویژگی‌های کلیدی:\n",
        "\n",
        "- استفاده از مدل‌های پایه با **الگوریتم‌های متنوع و مستقل**  \n",
        "- مدل نهایی می‌تواند **هر الگوریتمی** باشد (معمولاً ساده، مثل Logistic Regression یا XGBoost)  \n",
        "- مناسب برای مسائل پیچیده و **داده‌های نامتوازن**  \n",
        "- عملکرد کلی معمولاً بهتر از هر یک از مدل‌ها به‌تنهایی است\n",
        "\n",
        "---\n",
        "\n",
        "### 4️⃣ **Voting (Hard Voting / Soft Voting)**\n",
        "\n",
        "Voting یکی از روش‌های ساده و مؤثر انسمبل در یادگیری ماشین است که با ترکیب خروجی چند مدل مستقل، تصمیم نهایی را اتخاذ می‌کند. در این روش:\n",
        "\n",
        "1. یک دیتاست مشخص، به چندین مدل یادگیری ماشین با **الگوریتم‌های متفاوت** داده می‌شود.  \n",
        "2. هر مدل به‌صورت **مستقل و موازی** آموزش می‌بیند.  \n",
        "3. در زمان پیش‌بینی، خروجی تمام مدل‌ها گرفته شده و **ترکیب می‌شود** تا نتیجه نهایی تولید شود.\n",
        "\n",
        "### ✅ دو نوع اصلی Voting:\n",
        "\n",
        "- **Hard Voting:** انتخاب کلاسی که **بیشترین رأی** را از بین مدل‌ها کسب کرده باشد  \n",
        "- **Soft Voting:** انتخاب کلاسی که **بیشترین میانگین احتمال** را از بین مدل‌ها داشته باشد\n",
        "\n",
        "### 🗳️ نوع تصمیم‌گیری:\n",
        "\n",
        "- **Hard Voting** → اکثریت رأی‌ها (کدام کلاس بیشتر رأی آورده؟)  \n",
        "- **Soft Voting** → میانگین احتمال‌ها (کدام کلاس احتمال بیشتری دارد؟)\n",
        "\n",
        "### 🎯 ویژگی‌های کلیدی:\n",
        "\n",
        "- استفاده از مدل‌های متنوع (مثل Random Forest، KNN، SVM و ...)  \n",
        "- پیاده‌سازی آسان و مناسب برای شروع ترکیب مدل‌ها  \n",
        "- کاهش خطای کلی سیستم با **پوشش ضعف هر مدل توسط مدل‌های دیگر**  \n",
        "- Soft Voting معمولاً عملکرد دقیق‌تری نسبت به Hard Voting دارد\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "d87nrjnFdRme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### 📊 **مقایسه روش‌های انسمبل: Bagging، Boosting، Stacking و Voting**\n",
        "\n",
        "| ویژگی / روش          | **Bagging**                               | **Boosting**                                | **Stacking**                                  | **Voting**                                   |\n",
        "|----------------------|-------------------------------------------|---------------------------------------------|-----------------------------------------------|----------------------------------------------|\n",
        "| 🔁 **نوع آموزش**     | موازی و مستقل                            | زنجیره‌ای و وابسته                         | موازی در پایه، بعد یک مدل نهایی               | کاملاً مستقل و موازی                         |\n",
        "| 🧠 **مدل‌ها**        | یک الگوریتم (تکراری)                    | یک الگوریتم (تکراری)                        | الگوریتم‌های مختلف                            | الگوریتم‌های مختلف                           |\n",
        "| 🎯 **نحوه ترکیب**    | میانگین / رأی‌گیری                       | ترکیب وزن‌دار بر اساس خطای قبلی            | مدل نهایی (Meta Learner)                      | رأی‌گیری (Hard/Soft)                         |\n",
        "| 🎯 **هدف اصلی**     | کاهش واریانس (Variance)                  | کاهش بایاس (Bias) و افزایش دقت             | بهینه‌سازی ترکیبی از چند مدل پایه             | افزایش پایداری و دقت                        |\n",
        "| 🧪 **پیچیدگی پیاده‌سازی** | متوسط                                     | بالا                                        | نسبتاً بالا                                    | ساده                                          |\n",
        "| 💥 **نکته مهم**       | مدل‌ها از یک نوع هستن                   | آموزش مرحله‌به‌مرحله روی خطاها             | خروجی مدل‌های پایه ورودی مدل نهایی می‌شن      | فقط خروجی نهایی هر مدل بررسی می‌شه          |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "ZougWdVrlmmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "## ✅ مناسب‌ترین الگوریتم **انسمبل** برای دیتاست تو:\n",
        "\n",
        "### ✅ وقتی داده‌هات **از نوع متنی یا دسته‌ای (categorical)** باشن، مثل:\n",
        "\n",
        "- `merchant_name`\n",
        "- `category`\n",
        "- `gender`\n",
        "- `card_type`\n",
        "- `job`\n",
        "- `city`\n",
        "- و حتی `datetime` (اگر تبدیل به روز و ساعت بشه)\n",
        "\n",
        "\n",
        "\n",
        "### ❗ خیلی از الگوریتم‌ها با این نوع داده‌ها مشکل دارن، چون:\n",
        "\n",
        "- نیاز دارن تبدیلشون کنی به اعداد (مثل One-Hot یا Label Encoding)\n",
        "- یا بعد از تبدیل دقت کم می‌شه\n",
        "- یا overfitting می‌دن روی ویژگی‌های پرتکرار\n",
        "\n",
        "\n",
        "\n",
        "### 🥇 **CatBoost (Boosting-based Ensemble)**\n",
        "\n",
        "### 🎯 چرا CatBoost از همه بهتره برای تو؟\n",
        "\n",
        "| دلیل | توضیح |\n",
        "|------|--------|\n",
        "| 🎯 پشتیبانی مستقیم از ویژگی‌های دسته‌ای (`gender`, `job`, `category`, `merchant_name`, ...) | بدون نیاز به one-hot یا label encoding |\n",
        "| 🔍 قدرت بالا در کشف روابط پیچیده بین ویژگی‌ها | مناسب برای ویژگی‌های متنی و غیرخطی |\n",
        "| ⚖️ مقاومت در برابر overfitting | با تکنیک Ordered Boosting |\n",
        "| 📈 عملکرد بالا در داده‌های نامتوازن | در مقالات تقلب کارت اعتباری هم تأیید شده |\n",
        "| 🔧 تنظیمات راحت‌تر نسبت به XGBoost و LightGBM | برای دانشجوی ارشد با زمان محدود بسیار مناسب |\n",
        "| 🆕 کمتر تکراری در مقالات نسبت به XGBoost | باعث **نوآوری پایان‌نامه‌ات** می‌شه |\n",
        "| 📊 تفسیرپذیر با SHAP | عالی برای نوشتن مقاله و ارائه نتایج تحلیلی |\n",
        "\n",
        "\n",
        "\n",
        "### 🔍 سایر الگوریتم‌ها در برابر داده متنی:\n",
        "\n",
        "| الگوریتم | با categorical/text راحت کار می‌کنه؟ | نیاز به encoding |\n",
        "|----------|------------------------|--------------------|\n",
        "| **CatBoost** | ✅ بله، خودش انجام می‌ده | ❌ نیازی نیست |\n",
        "| **LightGBM** | ⚠️ بله، ولی باید Label Encoding بدی | ✅ نیاز داره |\n",
        "| **XGBoost** | ❌ نه، با categorical سازگار نیست | ✅ باید تبدیل کنی |\n",
        "| **Random Forest / Logistic / KNN** | ❌ نه | ✅ باید کامل تبدیل شه |\n",
        "\n",
        "\n",
        "\n",
        "### ✅ پیشنهاد نهایی:\n",
        "\n",
        "> برای پایان‌نامه‌ی تو، **CatBoost بهترین انتخاب انسمبلی است**.  \n",
        "> چون داده‌های اصلی تو پر از **ویژگی متنی و دسته‌ای هستن**،  \n",
        "> **CatBoost انتخاب شماره ۱ توئه** ✨  \n",
        "> هم به لحاظ **دقت**، هم **نوآوری**، هم **اجرا**، و هم **سازگاری با داده‌هات**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "yfKegcaOsV3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "## **✅ رتبه‌بندی نهایی Boosting Algorithms برای پروژه**\n",
        "\n",
        "### 📌 شرایطی که در نظر گرفته‌ایم:\n",
        "\n",
        "| شرط | ✅ در نظر گرفته شده؟ |\n",
        "|------|----------------------|\n",
        "| داده‌ها نامتوازن هستن | ✅ بله (تعداد تقلب‌ها بسیار کمتر از نرمال‌هاست) |\n",
        "| ستون‌ها معنای مشخص دارن (مثل gender, job...) | ✅ بله |\n",
        "| ویژگی‌های دسته‌ای (categorical) زیاد داریم | ✅ بله |\n",
        "| می‌خوای Feature Engineering و Selection انجام بدی | ✅ بله |\n",
        "| هدفت دقت بالا، تکراری نبودن، اجرا در Colab، و مقاله هست | ✅ دقیقاً همین |\n",
        "\n",
        "\n",
        "\n",
        "| رتبه | الگوریتم | چرا در این رتبه قرار گرفته؟ |\n",
        "|------|----------|-----------------------------|\n",
        "| 🥇 1 | **CatBoost** | 🔹 بهترین عملکرد برای داده‌های categorical بدون نیاز به encoding  \n",
        "🔹 کمترین نیاز به تنظیمات (hyperparameter tuning)  \n",
        "🔹 پشتیبانی قوی از missing values  \n",
        "🔹 بسیار مناسب برای دیتاست اروپا با ستون‌های نام‌دار  \n",
        "🔹 **کمتر کار شده → مناسب برای نوآوری** |\n",
        "| 🥈 2 | **LightGBM** | 🔹 بسیار سریع و کم‌مصرف  \n",
        "🔹 دقت بالا در داده‌های بزرگ  \n",
        "🔹 از categorical پشتیبانی می‌کنه ولی باید تبدیل کنی (label encoding)  \n",
        "🔹 اگر Feature Engineering قوی انجام بدی، نتیجه عالی می‌ده  \n",
        "🔸 نسبت به CatBoost کمی تکراری‌تر شده |\n",
        "| 🥉 3 | **XGBoost** | 🔹 دقت بالا و الگوریتمی امتحان‌شده  \n",
        "🔹 کنترل بالا روی پارامترها  \n",
        "🔸 نیاز به تنظیمات زیاد  \n",
        "🔸 پشتیبانی ضعیف‌تر برای داده‌های دسته‌ای  \n",
        "🔸 بسیار **تکراری** در مقالات تقلب؛ فقط در صورت نوآوری قابل استفاده است |\n",
        "\n",
        "\n",
        "\n",
        "### ✨ جمع‌بندی نهایی:\n",
        "\n",
        "| هدف تو | الگوریتم پیشنهادی |\n",
        "|--------|--------------------|\n",
        "| دقت + نوآوری + اجرا با داده‌های واقعی (نام‌دار) | ✅ **CatBoost** |\n",
        "| اجرا سریع + نتیجه خوب + امکان ترکیب با مهندسی ویژگی | ✅ **LightGBM** |\n",
        "| فقط در صورت نوآوری بسیار قوی | ⚠️ **XGBoost** |\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "IGmPHLgIb01S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "## **✅ رتبه‌بندی نهایی روش‌های متعادل‌سازی برای پروژه**\n",
        "\n",
        "\n",
        "### 📌 شرایط در نظر گرفته‌شده برای رتبه‌بندی:\n",
        "\n",
        "| شرط | ✅ بررسی‌شده |\n",
        "|------|---------------|\n",
        "| داده‌ها **نامتوازن و واقعی** هستن | ✅ بله |\n",
        "| ویژگی‌ها **نام‌دار و معنایی** هستن | ✅ بله |\n",
        "| **دقت مدل بسیار مهم**ه | ✅ کاملاً |\n",
        "| **اجرای ساده در Colab و Python** | ✅ باید عملی باشه |\n",
        "| می‌خوای با **مدل‌های Boosting** ترکیب کنی | ✅ بله |\n",
        "| می‌خوای مقالات تکراری نباشه | ✅ خیلی مهمه |\n",
        "\n",
        "\n",
        "\n",
        "| رتبه | روش متعادل‌سازی | چرا این رتبه؟ |\n",
        "|------|------------------|----------------|\n",
        "| 🥇 1 | **KMeans-SMOTE** | 🔹 داده‌های تقلب اغلب خوشه‌ای هستن؛ این روش خوشه‌بندی قبل از نمونه‌سازی انجام می‌ده  \n",
        "🔹 تولید داده واقعی‌تر نسبت به SMOTE ساده  \n",
        "🔹 بسیار مناسب برای داده‌های نام‌دار با ساختار رفتاری پیچیده  \n",
        "🔸 در مقالات کمتر استفاده شده → نوآورانه‌تر |\n",
        "| 🥈 2 | **SMOTE-ENN** | 🔹 ترکیب تولید نمونه جدید (SMOTE) با حذف نویز (ENN)  \n",
        "🔹 دقت بالا در کنار کاهش overfitting  \n",
        "🔹 عملکرد قوی با الگوریتم‌های Boosting  \n",
        "🔸 نسبتاً تکراری در مقالات |\n",
        "| 🥉 3 | **ADASYN** | 🔹 نمونه‌سازی هدفمند: تمرکز روی نقاط سخت‌تر برای طبقه‌بندی  \n",
        "🔹 قابل اجرا و مفید با مدل‌های LightGBM و CatBoost  \n",
        "🔸 گاهی باعث تولید داده‌های synthetic عجیب می‌شه |\n",
        "| 4️⃣ | **Borderline-SMOTE** | 🔹 تمرکز روی نقاط مرزی بین کلاس‌ها  \n",
        "🔸 اما اگر داده noisy باشه، ممکنه اشتباه تقویت کنه |\n",
        "| 5️⃣ | **SMOTE ساده** | 🔹 ساده‌ترین و رایج‌ترین  \n",
        "🔸 در مقالات زیاد تکرار شده  \n",
        "🔸 گاهی باعث overfitting یا تولید داده‌های غیرواقعی می‌شه |\n",
        "| 6️⃣ | **SMOTE-Tomek Links** | 🔹 حذف نقاط تکراری یا گیج‌کننده  \n",
        "🔸 اجرای پیچیده‌تر و در برخی موارد کاهش دقت نهایی |\n",
        "\n",
        "\n",
        "\n",
        "### ✨ جمع‌بندی پیشنهادی:\n",
        "\n",
        "| هدف تو | روش پیشنهادی |\n",
        "|--------|----------------|\n",
        "| نوآوری + عملکرد عالی + مقاله | ✅ **KMeans-SMOTE**  \n",
        "| تعادل بین دقت بالا و حذف نویز | ✅ **SMOTE-ENN**  \n",
        "| سرعت و سادگی + تنوع | ✅ **ADASYN** فقط در صورتی که KMeans-SMOTE اجرا نشد\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nMZHFgM3j1Wl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "\n",
        "### 🧩 **Feature Processing** یعنی چی؟\n",
        "\n",
        "**Feature Processing** یک اصطلاح **کلی و جامع**ه که شامل تمام عملیاتیه که روی ویژگی‌ها (Features) انجام می‌دیم تا اونا رو برای مدل آماده کنیم.\n",
        "\n",
        "یعنی:\n",
        "\n",
        "</div>\n",
        "\n",
        "> 🎯 **Feature Processing = Feature Engineering + Feature Selection + Normalization + Encoding + ...**\n",
        "\n",
        "<div dir=\"rtl\">\n",
        "\n",
        "\n",
        "### 📦 اجزای مهم Feature Processing:\n",
        "\n",
        "| مرحله | توضیح |\n",
        "|-------|--------|\n",
        "| 🛠 **Feature Engineering** | ساخت یا استخراج ویژگی‌های جدید از داده‌های خام |\n",
        "| ✂️ **Feature Selection** | انتخاب بهترین ویژگی‌ها و حذف اضافی‌ها |\n",
        "| 📐 **Normalization / Scaling** | نرمال‌سازی داده‌های عددی (مثلاً با MinMax یا StandardScaler) |\n",
        "| 🏷 **Encoding** | تبدیل ویژگی‌های دسته‌ای به عددی (مثل One-Hot, Label Encoding) |\n",
        "| 💫 **Transformation** | تبدیل‌های لگاریتمی، باینری، بُعدکاهش و... برای بهبود توزیع داده‌ها |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wkYA5VFrCy1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir=\"rtl\">\n",
        "  \n",
        "الان وقتشه که بر اساس **تمام داده‌هایی که چه عکسی یا متنی بهم دادی**، و با در نظر گرفتن:\n",
        "\n",
        "- ✅ دیتاست معنادار و غیر معنادار  \n",
        "- ✅ پایان‌نامه کارشناسی ارشد (با زمان ۱ سال و نیاز به نوآوری و قابلیت اجرا)  \n",
        "- ✅ هدف دقت بالا، مقاله‌پذیر بودن، اجرا در Colab  \n",
        "- ✅ ترکیب Boosting + Balancing + Feature Selection/Engineering  \n",
        "- ✅ **تکراری نبودن ترکیب** در مقالات  \n",
        "- ✅ **پشتیبانی قوی از categorical features**\n",
        "\n",
        "من بهت **نهایی‌ترین و دقیق‌ترین ترکیب‌ها** رو معرفی می‌کنم.\n",
        "\n",
        "# 🧪💎 **بهترین ترکیبات ممکن (کاملاً قابل دفاع، اجرا، و نوآورانه)**\n",
        "\n",
        "### ✅ جدول نهایی ترکیب‌های پیشنهادی برای کشف تقلب در کارت‌های اعتباری (CCFD)\n",
        "\n",
        "| 🔢 ردیف | 🎯 الگوریتم یادگیری | ⚖️ روش متعادل‌سازی داده | 🧠 Feature Processing |\n",
        "|--------|---------------------|---------------------------|------------------------|\n",
        "| 1️⃣ | CatBoost | KMeans-SMOTE | ✅ |\n",
        "| 2️⃣ | CatBoost | SMOTE-ENN | ✅ |\n",
        "| 3️⃣ | LightGBM | KMeans-SMOTE | ✅ |\n",
        "| 4️⃣ | CatBoost | ADASYN | ✅ |\n",
        "| 5️⃣ | XGBoost | KMeans-SMOTE | ✅ |\n",
        "\n",
        "---\n",
        "\n",
        "| پیشنهاد نهایی | ترکیب نهایی پیشنهادی |\n",
        "|----------------|------------------------|\n",
        "| اگر هدفت نوآوری + مقاله‌پذیری + اجراپذیری بالا باشه | ✅ **KMeans-SMOTE + CatBoost + Feature Processing** |\n",
        "| اگر اولویتت دقت و ساده بودن اجراست | ✅ **SMOTE-ENN + CatBoost + Feature Processing** |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "vWVg8KbgmMmM"
      }
    }
  ]
}