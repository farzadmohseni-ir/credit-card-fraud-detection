# 💳 Credit Card Fraud Detection

An **Ensemble-Based Machine Learning** approach for detecting credit card fraud, enhanced by advanced **data balancing techniques** to handle class imbalance challenges effectively.
### 🏷️ **موضوع: کشف تقلب در کارت‌های اعتباری**

---

### 📌 **تعریف موضوع:**

کشف تقلب در کارت‌های اعتباری یکی از مسائل مهم در حوزه‌ی علم داده و امنیت مالی است. با گسترش استفاده از پرداخت‌های دیجیتال و تراکنش‌های آنلاین، شناسایی سریع و دقیق فعالیت‌های متقلبانه برای بانک‌ها، شرکت‌های پرداخت و نهادهای مالی ضروری است.

---

### 🎯 **اهداف تحقیق:**

1. طراحی و توسعه یک سامانهٔ هوشمند به‌منظور افزایش دقت در شناسایی تراکنش‌های تقلبی.  
2. کاهش نرخ تشخیص نادرست تراکنش‌های سالم به‌ ‌عنوان تقلب (کاهش مثبت‌های کاذب).  
3. افزایش نرخ شناسایی صحیح تراکنش‌های تقلبی به‌ منظور ارتقاء امنیت سامانه‌های پرداخت.  
4. جلوگیری از آسیب به اعتبار مؤسسات مالی در اثر تصمیمات نادرست سیستم‌های تشخیص تقلب.  
5. حفظ رضایت و اعتماد مشتریان با کاهش موارد رد نادرست تراکنش‌های معتبر.

---

### ⚠️ **چالش‌های اصلی:**

- عدم توازن شدید بین کلاس‌های «تقلب» و «عدم تقلب» در داده‌ها.  
- وجود نویز و ویژگی‌های نامربوط در دیتاست.  
- دشواری در ارزیابی مدل‌ها به دلیل نرخ پایین وقوع تقلب (rare event).  
- ریسک بیش‌برازش (Overfitting) در مدل‌های پیچیده.  
- نیاز به پیاده‌سازی تکنیک‌های پیش‌پردازش و انتخاب ویژگی.

---


### 📊 مقایسه سه دیتاست معروف مرتبط با کشف تقلب در کارت‌های اعتباری
<div dir="rtl">
  
| ویژگی                          | ULB 2016               | Nelgiriyewithana - 2023      | IEEE-CIS 2019                   |
|:-------------------------------|:-------------------------------------|:------------------------------------------|:---------------------------------------------|
| 🏷️ عنوان دیتاست               | Credit Card Fraud Detection         | Credit Card Fraud Detection Dataset 2023  | IEEE-CIS Fraud Detection                     |
| 🌍 منبع                        | ULB (Université Libre de Bruxelles) | Kaggle (کاربر nelgiriyewithana)           | IEEE-CIS / Vesta Corporation                 |
| 📦 تعداد رکورد                | 284,807                             | 550,000                                    | 590,540                                      |
| 🔢 تعداد ویژگی                 | 30                                  | 30                                         | 431 (400 عددی + 31 دسته‌ای)                 |
| 🧩 نوع ویژگی‌ها               | ناشناس‌شده با PCA (فقط V1-V28)     | ناشناس‌شده (Amount, Category, etc.)       | ویژگی‌های متنوع دستگاه، کارت، آدرس، ایمیل و ... |
| 🔍 نرخ تقلب                    | 0.172٪ (492 مورد)                  | شدیداً نامتوازن (تعداد دقیق مشخص نیست)   | 3.5٪ (20,663 مورد)                           |
| 🎯 نوع برچسب هدف              | 0 (عادی) و 1 (تقلب)                | 0 (عادی) و 1 (تقلب)                        | 0 (عادی) و 1 (تقلب)                          |
| ⚙️ کاربردپذیری برای تحقیق     | بله (مرجع معتبر علمی)             | بله، مناسب برای نوآوری                    | بله، بسیار مناسب برای رقابت و مدل‌های پیشرفته |
| 📚 پیشنهاد شده برای           | مقایسه مدل‌ها (Benchmark)          | نوآوری در مدل‌ها و ویژگی‌سازی             | یادگیری عمیق، مهندسی ویژگی، AutoML و ...     |

</div>

---

### 🧠 جدول مراحل آماده‌سازی داده و مدل‌سازی
<div dir="rtl">

| 🔢 ردیف | مرحله                 | عنوان انگلیسی                    | شرح مختصر                                                                 |
|--------|------------------------|----------------------------------|---------------------------------------------------------------------------|
| 1      | 📥 جمع‌آوری داده        | Data Collection                  | دریافت داده‌ها از منابع معتبر مانند دیتاست‌های عمومی یا پایگاه‌های سازمانی |
| 2      | 🧾 درک داده             | Data Understanding               | تحلیل اولیه برای شناخت ساختار، انواع ویژگی‌ها و برچسب‌ها                 |
| 3      | 🧹 پاک‌سازی داده        | Data Cleaning                    | اصلاح داده‌های گمشده، حذف داده‌های پرت، و رفع ناسازگاری‌ها              |
| 4      | 🛠️ پیش‌پردازش داده      | Data Preprocessing               | نرمال‌سازی، کدگذاری داده‌های دسته‌ای، و آماده‌سازی ویژگی‌ها             |
| 5      | ⚖️ متعادل‌سازی داده     | Data Balancing                   | رفع مشکل نامتوازنی کلاس‌ها                                               |
| 6      | 📊 تحلیل اکتشافی        | Exploratory Data Analysis (EDA)  | بررسی آماری ویژگی‌ها، رسم نمودارها و بررسی توزیع داده‌ها                |
| 7      | 🧪 مهندسی ویژگی         | Feature Engineering              | ساخت ویژگی‌های جدید یا تبدیل ویژگی‌های موجود برای بهبود مدل            |
| 8      | 🎯 انتخاب ویژگی         | Feature Selection                | حذف ویژگی‌های کم‌اثر و انتخاب ویژگی‌های کلیدی با تکنیک‌های آماری        |
| 9      | ✂️ تقسیم‌بندی داده       | Train-Test Split                 | جداسازی داده به مجموعه آموزش و آزمون برای ارزیابی مدل                    |
| 10     | 🤖 مدل‌سازی             | Modeling                         | آموزش مدل با الگوریتم‌های مناسب و تنظیم پارامترها                        |

</div>

---

### ⚖️ جدول نهایی روش‌های متعادل‌سازی داده (با مزایا، معایب، توضیح عملکرد و تناسب با دیتاست)

<div dir="rtl">


| 🔢 ردیف | 🧪 عنوان روش | 🧬 نوع | 🧩 توضیح روش | ✅ مزایا | ⚠️ معایب | 📊 مناسب برای دیتاست من؟ |
|--------|--------------|--------|--------------|---------|----------|----------------------------|
| 1      | Random Undersampling | Undersampling | با حذف تصادفی از کلاس غالب، کلاس‌ها را برابر می‌کند. | ساده و سریع، کاهش حجم داده | احتمال حذف اطلاعات مفید | ❌ خیلی ضعیف برای دیتاست بزرگ و نامتوازن |
| 2      | Random Oversampling | Oversampling | با تکرار تصادفی نمونه‌های کلاس اقلیت، تعادل ایجاد می‌کند. | حفظ داده‌ها، اجرای آسان | احتمال بیش‌برازش | ⚠️ فقط برای تست‌های اولیه یا مدل‌های ساده پیشنهاد می‌شود |
| 3      | SMOTE | Oversampling | داده‌های مصنوعی بین نزدیک‌ترین همسایه‌ها تولید می‌کند. | تولید داده‌های متنوع، کاهش Overfitting | ممکن است داده مصنوعی نامعتبر تولید کند | ✅ مناسب، مخصوصاً برای شروع مدل‌سازی و مقایسه |
| 4      | Borderline-SMOTE | Oversampling | فقط اطراف مرز کلاس‌ها نمونه‌سازی می‌کند. | تمرکز بر نقاط بحرانی، افزایش دقت | حساس به نویز | ✅ مناسب، به‌ویژه برای مدل‌های دقیق‌تر |
| 5      | ADASYN | Oversampling | در نواحی سخت‌تر، داده بیشتری تولید می‌کند. | تطبیق‌پذیر، تنوع بالا | ممکن است داده غیرواقعی تولید شود | ✅ مناسب برای مدل‌های پیچیده‌تر |
| 6      | SMOTE-ENN | Hybrid | پس از SMOTE، نمونه‌های نویزی را با ENN حذف می‌کند. | حذف نویز، داده تمیزتر | پیچیده‌تر و زمان‌بر | ✅ بسیار مناسب، مخصوصاً اگر دقت مهم باشد |
| 7      | SMOTE-Tomek | Hybrid | SMOTE + حذف نمونه‌های متداخل با Tomek Links | حذف همپوشانی کلاس‌ها | پردازش بیشتر نیاز دارد | ✅ مناسب برای حذف داده‌های مبهم و مرزی |
| 8      | KMeans-SMOTE | Oversampling هوشمند | با خوشه‌بندی قبل از SMOTE، داده متعادل و متنوع‌تری تولید می‌کند. | متنوع، کاهش Overfitting | نیاز به تنظیم دقیق K | ✅✅ بسیار مناسب برای دیتاست بزرگ و واقعی تو |



</div>

📌 **راهنمای علامت‌ها:**  
- ✅ پیشنهاد می‌شود  
- ✅✅ کاملاً توصیه می‌شود  
- ⚠️ قابل استفاده ولی نه بهترین انتخاب  
- ❌ مناسب نیست برای دیتاست تو

---


### 📊 دسته‌بندی روش‌های مدل‌سازی در کشف تقلب کارت اعتباری (CCFD)

<div dir="rtl">
  
| 🔢 ردیف | 🧠 دسته روش              | 🔤 عنوان انگلیسی               | 🧪 الگوریتم‌ها                                                                 |
|--------|---------------------------|--------------------------------|--------------------------------------------------------------------------------|
| 1️⃣     | یادگیری ماشین             | Machine Learning               | Decision Tree, Logistic Regression, SVM, Naive Bayes, KNN                      |
| 2️⃣     | یادگیری انسمبل            | Ensemble Learning              | Random Forest, AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost        |
| 3️⃣     | یادگیری عمیق             | Deep Learning                  | MLP, CNN, RNN, LSTM, Autoencoder                                               |
| 4️⃣     | یادگیری ترکیبی           | Hybrid Learning                | ML + DL، Rule-Based + ML، Stacking، Blending                                   |
| 5️⃣     | مدل‌های گرافی             | Graph-Based Models             | GCN، GAT، GraphSAGE، Graph Attention Network، GATv2                            |
| 6️⃣     | کشف ناهنجاری             | Anomaly Detection              | Isolation Forest، One-Class SVM، LOF، Autoencoder (Unsupervised)              |
| 7️⃣     | یادگیری نیمه‌نظارتی       | Semi-Supervised Learning       | Label Propagation، Self-Training، Semi-Supervised SVM، Co-Training             |
| 8️⃣     | یادگیری تقویتی            | Reinforcement Learning         | Q-Learning، Deep Q-Network (DQN)، SARSA، Policy Gradient                      |
| 9️⃣     | یادگیری بدون نظارت        | Unsupervised Learning          | KMeans، DBSCAN، PCA، Autoencoder (Unsupervised)                               |

</div>

---

### ✳️ جدول موضوعات پایان‌نامه بر اساس دسته‌بندی روش‌های مدل‌سازی در کشف تقلب کارت‌های اعتباری 💳🧠📊

<div dir="rtl">

| 🔢 ردیف | 🎓📘 عنوان پیشنهادی پایان‌نامه (فارسی / English) |
|--------|---------------------------------------------------|
| 1️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از تکنیک‌های متعادل‌سازی داده و الگوریتم‌های یادگیری ماشین  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Data Balancing Techniques and Classical Machine Learning Algorithms* |
| 2️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های انسمبل و تکنیک‌های متعادل‌سازی داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Ensemble Models and Data Balancing Techniques* |
| 3️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از الگوریتم‌های یادگیری عمیق و رویکردهای مقابله با عدم‌توازن داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Deep Learning Algorithms and Imbalanced Data Handling Approaches* |
| 4️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های ترکیبی و تکنیک‌های متعادل‌سازی داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Hybrid Models and Data Balancing Techniques* |
| 5️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های مبتنی بر گراف و روش‌های مقابله با عدم‌توازن داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Graph-Based Models and Imbalanced Data Handling Techniques* |
| 6️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از روش‌های کشف ناهنجاری و تکنیک‌های متعادل‌سازی داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Anomaly Detection Methods and Data Balancing Techniques* |
| 7️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از یادگیری نیمه‌نظارتی و روش‌های مدیریت داده‌های نامتوازن  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Semi-Supervised Learning and Imbalanced Data Handling Techniques* |
| 8️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از یادگیری تقویتی و تکنیک‌های مقابله با داده‌های نامتوازن  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Reinforcement Learning and Imbalanced Data Handling Approaches* |
| 9️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از الگوریتم‌های یادگیری بدون نظارت و تحلیل داده‌های نامتوازن  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Unsupervised Learning Algorithms and Imbalanced Data Analysis* |


</div>


---


### ✔️ مسیر پیشنهادی نهایی برای پایان‌نامه:



### 🧠 مدل‌های انسمبل چیستند؟  
مدل‌های انسمبل مجموعه‌ای از الگوریتم‌های یادگیری ماشین هستند که به‌جای تکیه بر یک مدل واحد، چندین مدل پایه را ترکیب می‌کنند تا یک تصمیم نهایی دقیق‌تر، پایدارتر و قابل اعتمادتر ارائه دهند.  

ایده اصلی انسمبل این است که «ترکیب چند مدل ضعیف، می‌تواند منجر به یک مدل قوی‌تر شود» – درست مانند خرد جمعی.



### 💡 مزایای کلیدی انسمبل:

- **🎯 افزایش دقت:** با ترکیب چند مدل، خطاهای فردی کاهش می‌یابد.  
- **🛡️ کاهش overfitting:** به‌ویژه در داده‌های نامتوازن مثل CCFD بسیار مؤثر است.  
- **📊 پایداری بیشتر:** خروجی نهایی از چند زاویه بررسی می‌شود، نه فقط یک دیدگاه.  
- **🧪 انعطاف‌پذیری:** می‌توان مدل‌ها را از خانواده‌های مختلف ترکیب کرد (مثلاً Tree و Boost).



### 🎯 مدل‌های انسمبل زیرمجموعه کدام دسته‌اند؟  
### ⛓️ ساختار سلسله‌مراتبی:

هوش مصنوعی (AI)  
└── یادگیری ماشین (Machine Learning)  
&emsp;└── یادگیری نظارت‌شده (Supervised Learning)  
&emsp;&emsp;└── مدل‌های انسمبل (Ensemble Models)



### ✳️ چرا برای پایان‌نامه ما مناسب است؟  
در مسئله کشف تقلب در کارت‌های اعتباری، داده‌ها به‌شدت نامتوازن و حساس‌اند. انسمبل‌ها با قدرت ترکیب و تعمیم، می‌توانند خطاهای تشخیص را کاهش داده، دقت را بالا برده و راهکاری قوی‌تر از مدل‌های ساده ارائه کنند.


---

<span dir="ltr">

  
## 🎯 انواع مدل‌های انسمبل (Ensemble Models)


### 1️⃣ **Bagging (Bootstrap Aggregating)**

📌 یکی از تکنیک‌های ساده و مؤثر برای کاهش **واریانس** و افزایش **پایداری** مدل‌ها.

**نحوه عملکرد:**

1. ساخت چندین **زیرمجموعه تصادفی با جایگزینی** از داده اصلی (Bootstrapped Samples)  
2. آموزش مدل‌های مشابه (مثلاً فقط درخت تصمیم) روی هر زیرمجموعه  
3. ترکیب خروجی‌ها با:  
   • رأی‌گیری اکثریت (برای طبقه‌بندی)  
   • میانگین‌گیری (برای رگرسیون)

✅ **ویژگی‌های کلیدی:**

- استفاده از **یک الگوریتم ثابت** برای همه مدل‌ها  
- تفاوت فقط در **نمونه‌های آموزش تصادفی**  
- مقاوم در برابر **نویز** و مناسب برای **داده‌های ناپایدار**  
- ترکیب خروجی‌ها باعث افزایش **دقت و پایداری** می‌شود

---

### 2️⃣ **Boosting**

📌 روشی قدرتمند برای کاهش **بایاس** و افزایش **دقت مدل** با آموزش زنجیره‌ای مدل‌ها.

**نحوه عملکرد:**

1. آموزش مدل‌های ضعیف به‌صورت **ترتیبی و مرحله‌ای**  
2. تمرکز هر مدل جدید روی **خطاهای مدل قبلی**  
3. ترکیب نهایی با **وزن‌دهی به پیش‌بینی‌ها**

✅ **ویژگی‌های کلیدی:**

- یادگیری **وابسته و مرحله‌به‌مرحله**  
- الگوریتم مشابه برای همه مدل‌ها  
- تاکید روی **نمونه‌های سخت‌تر**  
- عالی برای **داده‌های نامتوازن و پیچیده**

---

### 3️⃣ **Stacking (Stacked Generalization)**

📌 روشی پیشرفته برای ترکیب خروجی چند مدل متفاوت و ارائه به یک **مدل نهایی هوشمند (Meta Learner)**.

**نحوه عملکرد:**

1. اجرای چندین مدل با الگوریتم‌های مختلف (SVM، KNN، RF و...)  
2. گرفتن خروجی‌ها و ساخت **ویژگی‌های جدید**  
3. آموزش مدل نهایی روی این ویژگی‌ها

✅ **ویژگی‌های کلیدی:**

- ترکیب **مدل‌های متنوع و مستقل**  
- Meta Learner معمولاً مدل ساده‌ایه مثل Logistic Regression  
- عملکرد بهتر نسبت به مدل‌های تکی  
- مناسب برای **مسائل پیچیده و نامتوازن**

---

### 4️⃣ **Voting (Hard Voting / Soft Voting)**

📌 ترکیب پیش‌بینی چند مدل مستقل برای تصمیم‌گیری نهایی.

**نحوه عملکرد:**

1. آموزش مدل‌های مختلف به‌صورت **موازی و مستقل**  
2. گرفتن پیش‌بینی از هر مدل  
3. تصمیم‌گیری با ترکیب خروجی‌ها

✅ **دو نوع اصلی Voting:**

- **Hard Voting:** انتخاب بر اساس اکثریت رأی  
- **Soft Voting:** انتخاب بر اساس میانگین احتمال

🗳️ **نوع تصمیم‌گیری:**

- Hard Voting → کدام کلاس بیشتر رأی آورده؟  
- Soft Voting → کدام کلاس احتمال بیشتری دارد؟

🎯 **ویژگی‌های کلیدی:**

- استفاده از **الگوریتم‌های متنوع**  
- بسیار ساده برای پیاده‌سازی اولیه  
- هر مدل ضعف بقیه رو **پوشش می‌ده**  
- Soft Voting معمولاً **دقیق‌تره**

</span>
