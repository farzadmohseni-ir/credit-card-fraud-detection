# 💳 Credit Card Fraud Detection

An **Ensemble-Based Machine Learning** approach for detecting credit card fraud, enhanced by advanced **data balancing techniques** to handle class imbalance challenges effectively.
### 🏷️ **موضوع: کشف تقلب در کارت‌های اعتباری**

---

### 📌 **تعریف موضوع:**

کشف تقلب در کارت‌های اعتباری یکی از مسائل مهم در حوزه‌ی علم داده و امنیت مالی است. با گسترش استفاده از پرداخت‌های دیجیتال و تراکنش‌های آنلاین، شناسایی سریع و دقیق فعالیت‌های متقلبانه برای بانک‌ها، شرکت‌های پرداخت و نهادهای مالی ضروری است.

---

### 🎯 **اهداف تحقیق:**

1. طراحی و توسعه یک سامانهٔ هوشمند به‌منظور افزایش دقت در شناسایی تراکنش‌های تقلبی.  
2. کاهش نرخ تشخیص نادرست تراکنش‌های سالم به‌ ‌عنوان تقلب (کاهش مثبت‌های کاذب).  
3. افزایش نرخ شناسایی صحیح تراکنش‌های تقلبی به‌ منظور ارتقاء امنیت سامانه‌های پرداخت.  
4. جلوگیری از آسیب به اعتبار مؤسسات مالی در اثر تصمیمات نادرست سیستم‌های تشخیص تقلب.  
5. حفظ رضایت و اعتماد مشتریان با کاهش موارد رد نادرست تراکنش‌های معتبر.

---

### ⚠️ **چالش‌های اصلی:**

- عدم توازن شدید بین کلاس‌های «تقلب» و «عدم تقلب» در داده‌ها.  
- وجود نویز و ویژگی‌های نامربوط در دیتاست.  
- دشواری در ارزیابی مدل‌ها به دلیل نرخ پایین وقوع تقلب (rare event).  
- ریسک بیش‌برازش (Overfitting) در مدل‌های پیچیده.  
- نیاز به پیاده‌سازی تکنیک‌های پیش‌پردازش و انتخاب ویژگی.

---


### 📊 مقایسه سه دیتاست معروف مرتبط با کشف تقلب در کارت‌های اعتباری
<div dir="rtl">
  
| ویژگی                          | دیتاست اول (ULB 2016)               | دیتاست دوم (Nelgiriyewithana - 2023)      | دیتاست سوم (IEEE-CIS 2019)                   |
|:-------------------------------|:-------------------------------------|:------------------------------------------|:---------------------------------------------|
| 🏷️ عنوان دیتاست               | Credit Card Fraud Detection         | Credit Card Fraud Detection Dataset 2023  | IEEE-CIS Fraud Detection                     |
| 🌍 منبع                        | ULB (Université Libre de Bruxelles) | Kaggle (کاربر nelgiriyewithana)           | IEEE-CIS / Vesta Corporation                 |
| 📦 تعداد رکورد                | 284,807                             | 550,000                                    | 590,540                                      |
| 🔢 تعداد ویژگی                 | 30                                  | 30                                         | 431 (400 عددی + 31 دسته‌ای)                 |
| 🧩 نوع ویژگی‌ها               | ناشناس‌شده با PCA (فقط V1-V28)     | ناشناس‌شده (Amount, Category, etc.)       | ویژگی‌های متنوع دستگاه، کارت، آدرس، ایمیل و ... |
| 🔍 نرخ تقلب                    | 0.172٪ (492 مورد)                  | شدیداً نامتوازن (تعداد دقیق مشخص نیست)   | 3.5٪ (20,663 مورد)                           |
| 🎯 نوع برچسب هدف              | 0 (عادی) و 1 (تقلب)                | 0 (عادی) و 1 (تقلب)                        | 0 (عادی) و 1 (تقلب)                          |
| ⚙️ کاربردپذیری برای تحقیق     | بله (مرجع معتبر علمی)             | بله، مناسب برای نوآوری                    | بله، بسیار مناسب برای رقابت و مدل‌های پیشرفته |
| 📚 پیشنهاد شده برای           | مقایسه مدل‌ها (Benchmark)          | نوآوری در مدل‌ها و ویژگی‌سازی             | یادگیری عمیق، مهندسی ویژگی، AutoML و ...     |

</div>

---

### 🧠 جدول مراحل آماده‌سازی داده و مدل‌سازی
<div dir="rtl">

| 🔢 ردیف | مرحله                 | عنوان انگلیسی                    | شرح مختصر                                                                 |
|--------|------------------------|----------------------------------|---------------------------------------------------------------------------|
| 1      | 📥 جمع‌آوری داده        | Data Collection                  | دریافت داده‌ها از منابع معتبر مانند دیتاست‌های عمومی یا پایگاه‌های سازمانی |
| 2      | 🧾 درک داده             | Data Understanding               | تحلیل اولیه برای شناخت ساختار، انواع ویژگی‌ها و برچسب‌ها                 |
| 3      | 🧹 پاک‌سازی داده        | Data Cleaning                    | اصلاح داده‌های گمشده، حذف داده‌های پرت، و رفع ناسازگاری‌ها              |
| 4      | 🛠️ پیش‌پردازش داده      | Data Preprocessing               | نرمال‌سازی، کدگذاری داده‌های دسته‌ای، و آماده‌سازی ویژگی‌ها             |
| 5      | ⚖️ متعادل‌سازی داده     | Data Balancing                   | رفع مشکل نامتوازنی کلاس‌ها                                               |
| 6      | 📊 تحلیل اکتشافی        | Exploratory Data Analysis (EDA)  | بررسی آماری ویژگی‌ها، رسم نمودارها و بررسی توزیع داده‌ها                |
| 7      | 🧪 مهندسی ویژگی         | Feature Engineering              | ساخت ویژگی‌های جدید یا تبدیل ویژگی‌های موجود برای بهبود مدل            |
| 8      | 🎯 انتخاب ویژگی         | Feature Selection                | حذف ویژگی‌های کم‌اثر و انتخاب ویژگی‌های کلیدی با تکنیک‌های آماری        |
| 9      | ✂️ تقسیم‌بندی داده       | Train-Test Split                 | جداسازی داده به مجموعه آموزش و آزمون برای ارزیابی مدل                    |
| 10     | 🤖 مدل‌سازی             | Modeling                         | آموزش مدل با الگوریتم‌های مناسب و تنظیم پارامترها                        |

</div>

---

### ⚖️ جدول نهایی روش‌های متعادل‌سازی داده (با مزایا، معایب، توضیح عملکرد و تناسب با دیتاست)

<div dir="rtl">


| 🔢 ردیف | عنوان روش             | نوع                   | مزایا                                           | معایب                                  | مناسب برای دیتاست 2023؟                      |
|--------|------------------------|------------------------|--------------------------------------------------|-----------------------------------------|----------------------------------------------|
| 1      | Random Undersampling   | Undersampling          | ساده و سریع، کاهش حجم داده                      | احتمال حذف اطلاعات مفید               | ❌ خیلی ضعیف برای دیتاست بزرگ و نامتوازن     |
|        |                        |                        | ➤ با حذف تصادفی از کلاس غالب، کلاس‌ها را برابر می‌کند. |                                         |                                              |
| 2      | Random Oversampling    | Oversampling           | حفظ داده‌ها، اجرای آسان                         | احتمال بیش‌برازش                       | ⚠️ فقط برای تست‌های اولیه یا مدل‌های ساده پیشنهاد می‌شود |
|        |                        |                        | ➤ با تکرار تصادفی نمونه‌های کلاس اقلیت، تعادل ایجاد می‌کند. |                                         |                                              |
| 3      | SMOTE                  | Oversampling           | تولید داده‌های متنوع، کاهش Overfitting          | ممکن است داده مصنوعی نامعتبر تولید کند | ✅ مناسب، مخصوصاً برای شروع مدل‌سازی و مقایسه |
|        |                        |                        | ➤ داده‌های مصنوعی بین نزدیک‌ترین همسایه‌ها تولید می‌کند. |                                         |                                              |
| 4      | Borderline-SMOTE       | Oversampling           | تمرکز بر نقاط بحرانی، افزایش دقت                | حساس به نویز                           | ✅ مناسب، به‌ویژه برای مدل‌های دقیق‌تر        |
|        |                        |                        | ➤ فقط اطراف مرز کلاس‌ها نمونه‌سازی می‌کند.      |                                         |                                              |
| 5      | ADASYN                 | Oversampling           | تطبیق‌پذیر، تنوع بالا                            | ممکن است داده غیرواقعی تولید شود       | ✅ مناسب برای مدل‌های پیچیده‌تر               |
|        |                        |                        | ➤ در نواحی سخت‌تر، داده بیشتری تولید می‌کند.    |                                         |                                              |
| 6      | SMOTE-ENN              | Hybrid                 | حذف نویز، داده تمیزتر                            | پیچیده‌تر و زمان‌بر                    | ✅ بسیار مناسب، مخصوصاً اگر دقت مهم باشد     |
|        |                        |                        | ➤ پس از SMOTE، نمونه‌های نویزی را با ENN حذف می‌کند. |                                      |                                              |
| 7      | SMOTE-Tomek            | Hybrid                 | حذف همپوشانی کلاس‌ها                             | پردازش بیشتر نیاز دارد                 | ✅ مناسب برای حذف داده‌های مبهم و مرزی        |
|        |                        |                        | ➤ SMOTE + حذف نمونه‌های متداخل با Tomek Links  |                                         |                                              |
| 8      | KMeans-SMOTE           | Oversampling هوشمند   | متنوع، کاهش Overfitting                         | نیاز به تنظیم دقیق K                  | ✅✅ بسیار مناسب برای دیتاست بزرگ و واقعی تو   |
|        |                        |                        | ➤ با خوشه‌بندی قبل از SMOTE، داده متعادل و متنوع‌تری تولید می‌کند. |                                 |                                              |

</div>

📌 **راهنمای علامت‌ها:**  
- ✅ پیشنهاد می‌شود  
- ✅✅ کاملاً توصیه می‌شود  
- ⚠️ قابل استفاده ولی نه بهترین انتخاب  
- ❌ مناسب نیست برای دیتاست تو
