# 💳 Credit Card Fraud Detection

An **Ensemble-Based Machine Learning** approach for detecting credit card fraud, enhanced by advanced **data balancing techniques** to handle class imbalance challenges effectively.
### 🏷️ **موضوع: کشف تقلب در کارت‌های اعتباری**

---

### 📌 **تعریف موضوع:**

کشف تقلب در کارت‌های اعتباری یکی از مسائل مهم در حوزه‌ی علم داده و امنیت مالی است. با گسترش استفاده از پرداخت‌های دیجیتال و تراکنش‌های آنلاین، شناسایی سریع و دقیق فعالیت‌های متقلبانه برای بانک‌ها، شرکت‌های پرداخت و نهادهای مالی ضروری است.

---

### 🎯 **اهداف تحقیق:**

1. طراحی و توسعه یک سامانهٔ هوشمند به‌منظور افزایش دقت در شناسایی تراکنش‌های تقلبی.  
2. کاهش نرخ تشخیص نادرست تراکنش‌های سالم به‌ ‌عنوان تقلب (کاهش مثبت‌های کاذب).  
3. افزایش نرخ شناسایی صحیح تراکنش‌های تقلبی به‌ منظور ارتقاء امنیت سامانه‌های پرداخت.  
4. جلوگیری از آسیب به اعتبار مؤسسات مالی در اثر تصمیمات نادرست سیستم‌های تشخیص تقلب.  
5. حفظ رضایت و اعتماد مشتریان با کاهش موارد رد نادرست تراکنش‌های معتبر.

---

### ⚠️ **چالش‌های اصلی:**

- عدم توازن شدید بین کلاس‌های «تقلب» و «عدم تقلب» در داده‌ها.  
- وجود نویز و ویژگی‌های نامربوط در دیتاست.  
- دشواری در ارزیابی مدل‌ها به دلیل نرخ پایین وقوع تقلب (rare event).  
- ریسک بیش‌برازش (Overfitting) در مدل‌های پیچیده.  
- نیاز به پیاده‌سازی تکنیک‌های پیش‌پردازش و انتخاب ویژگی.

---


### 📊 مقایسه سه دیتاست معروف مرتبط با کشف تقلب در کارت‌های اعتباری
<div dir="rtl">
  
| ویژگی                          | دیتاست اول (ULB 2016)               | دیتاست دوم (Nelgiriyewithana - 2023)      | دیتاست سوم (IEEE-CIS 2019)                   |
|:-------------------------------|:-------------------------------------|:------------------------------------------|:---------------------------------------------|
| 🏷️ عنوان دیتاست               | Credit Card Fraud Detection         | Credit Card Fraud Detection Dataset 2023  | IEEE-CIS Fraud Detection                     |
| 🌍 منبع                        | ULB (Université Libre de Bruxelles) | Kaggle (کاربر nelgiriyewithana)           | IEEE-CIS / Vesta Corporation                 |
| 📦 تعداد رکورد                | 284,807                             | 550,000                                    | 590,540                                      |
| 🔢 تعداد ویژگی                 | 30                                  | 30                                         | 431 (400 عددی + 31 دسته‌ای)                 |
| 🧩 نوع ویژگی‌ها               | ناشناس‌شده با PCA (فقط V1-V28)     | ناشناس‌شده (Amount, Category, etc.)       | ویژگی‌های متنوع دستگاه، کارت، آدرس، ایمیل و ... |
| 🔍 نرخ تقلب                    | 0.172٪ (492 مورد)                  | شدیداً نامتوازن (تعداد دقیق مشخص نیست)   | 3.5٪ (20,663 مورد)                           |
| 🎯 نوع برچسب هدف              | 0 (عادی) و 1 (تقلب)                | 0 (عادی) و 1 (تقلب)                        | 0 (عادی) و 1 (تقلب)                          |
| ⚙️ کاربردپذیری برای تحقیق     | بله (مرجع معتبر علمی)             | بله، مناسب برای نوآوری                    | بله، بسیار مناسب برای رقابت و مدل‌های پیشرفته |
| 📚 پیشنهاد شده برای           | مقایسه مدل‌ها (Benchmark)          | نوآوری در مدل‌ها و ویژگی‌سازی             | یادگیری عمیق، مهندسی ویژگی، AutoML و ...     |

</div>

---

### 🧠 جدول مراحل آماده‌سازی داده و مدل‌سازی
<div dir="rtl">

| 🔢 ردیف | مرحله                 | عنوان انگلیسی                    | شرح مختصر                                                                 |
|--------|------------------------|----------------------------------|---------------------------------------------------------------------------|
| 1      | 📥 جمع‌آوری داده        | Data Collection                  | دریافت داده‌ها از منابع معتبر مانند دیتاست‌های عمومی یا پایگاه‌های سازمانی |
| 2      | 🧾 درک داده             | Data Understanding               | تحلیل اولیه برای شناخت ساختار، انواع ویژگی‌ها و برچسب‌ها                 |
| 3      | 🧹 پاک‌سازی داده        | Data Cleaning                    | اصلاح داده‌های گمشده، حذف داده‌های پرت، و رفع ناسازگاری‌ها              |
| 4      | 🛠️ پیش‌پردازش داده      | Data Preprocessing               | نرمال‌سازی، کدگذاری داده‌های دسته‌ای، و آماده‌سازی ویژگی‌ها             |
| 5      | ⚖️ متعادل‌سازی داده     | Data Balancing                   | رفع مشکل نامتوازنی کلاس‌ها                                               |
| 6      | 📊 تحلیل اکتشافی        | Exploratory Data Analysis (EDA)  | بررسی آماری ویژگی‌ها، رسم نمودارها و بررسی توزیع داده‌ها                |
| 7      | 🧪 مهندسی ویژگی         | Feature Engineering              | ساخت ویژگی‌های جدید یا تبدیل ویژگی‌های موجود برای بهبود مدل            |
| 8      | 🎯 انتخاب ویژگی         | Feature Selection                | حذف ویژگی‌های کم‌اثر و انتخاب ویژگی‌های کلیدی با تکنیک‌های آماری        |
| 9      | ✂️ تقسیم‌بندی داده       | Train-Test Split                 | جداسازی داده به مجموعه آموزش و آزمون برای ارزیابی مدل                    |
| 10     | 🤖 مدل‌سازی             | Modeling                         | آموزش مدل با الگوریتم‌های مناسب و تنظیم پارامترها                        |

</div>

---

### ⚖️ جدول نهایی روش‌های متعادل‌سازی داده (با مزایا، معایب، توضیح عملکرد و تناسب با دیتاست)

<div dir="rtl">


| 🔢 ردیف | عنوان روش             | نوع                   | مزایا                                           | معایب                                  | مناسب برای دیتاست من؟                      |
|--------|------------------------|------------------------|--------------------------------------------------|-----------------------------------------|----------------------------------------------|
| 1      | Random Undersampling   | Undersampling          | ساده و سریع، کاهش حجم داده                      | احتمال حذف اطلاعات مفید               | ❌ خیلی ضعیف برای دیتاست بزرگ و نامتوازن     |
|        |                        |                        | ➤ با حذف تصادفی از کلاس غالب، کلاس‌ها را برابر می‌کند. |                                         |                                              |
| 2      | Random Oversampling    | Oversampling           | حفظ داده‌ها، اجرای آسان                         | احتمال بیش‌برازش                       | ⚠️ فقط برای تست‌های اولیه یا مدل‌های ساده پیشنهاد می‌شود |
|        |                        |                        | ➤ با تکرار تصادفی نمونه‌های کلاس اقلیت، تعادل ایجاد می‌کند. |                                         |                                              |
| 3      | SMOTE                  | Oversampling           | تولید داده‌های متنوع، کاهش Overfitting          | ممکن است داده مصنوعی نامعتبر تولید کند | ✅ مناسب، مخصوصاً برای شروع مدل‌سازی و مقایسه |
|        |                        |                        | ➤ داده‌های مصنوعی بین نزدیک‌ترین همسایه‌ها تولید می‌کند. |                                         |                                              |
| 4      | Borderline-SMOTE       | Oversampling           | تمرکز بر نقاط بحرانی، افزایش دقت                | حساس به نویز                           | ✅ مناسب، به‌ویژه برای مدل‌های دقیق‌تر        |
|        |                        |                        | ➤ فقط اطراف مرز کلاس‌ها نمونه‌سازی می‌کند.      |                                         |                                              |
| 5      | ADASYN                 | Oversampling           | تطبیق‌پذیر، تنوع بالا                            | ممکن است داده غیرواقعی تولید شود       | ✅ مناسب برای مدل‌های پیچیده‌تر               |
|        |                        |                        | ➤ در نواحی سخت‌تر، داده بیشتری تولید می‌کند.    |                                         |                                              |
| 6      | SMOTE-ENN              | Hybrid                 | حذف نویز، داده تمیزتر                            | پیچیده‌تر و زمان‌بر                    | ✅ بسیار مناسب، مخصوصاً اگر دقت مهم باشد     |
|        |                        |                        | ➤ پس از SMOTE، نمونه‌های نویزی را با ENN حذف می‌کند. |                                      |                                              |
| 7      | SMOTE-Tomek            | Hybrid                 | حذف همپوشانی کلاس‌ها                             | پردازش بیشتر نیاز دارد                 | ✅ مناسب برای حذف داده‌های مبهم و مرزی        |
|        |                        |                        | ➤ SMOTE + حذف نمونه‌های متداخل با Tomek Links  |                                         |                                              |
| 8      | KMeans-SMOTE           | Oversampling هوشمند   | متنوع، کاهش Overfitting                         | نیاز به تنظیم دقیق K                  | ✅✅ بسیار مناسب برای دیتاست بزرگ و واقعی تو   |
|        |                        |                        | ➤ با خوشه‌بندی قبل از SMOTE، داده متعادل و متنوع‌تری تولید می‌کند. |                                 |                                              |

</div>

📌 **راهنمای علامت‌ها:**  
- ✅ پیشنهاد می‌شود  
- ✅✅ کاملاً توصیه می‌شود  
- ⚠️ قابل استفاده ولی نه بهترین انتخاب  
- ❌ مناسب نیست برای دیتاست تو

---


### 📊 دسته‌بندی روش‌های مدل‌سازی در کشف تقلب کارت اعتباری (CCFD)

<div dir="rtl">
  
| 🔢 ردیف | 🧠 دسته روش              | 🔤 عنوان انگلیسی               | 🧪 الگوریتم‌ها                                                                 |
|--------|---------------------------|--------------------------------|--------------------------------------------------------------------------------|
| 1️⃣     | یادگیری ماشین             | Machine Learning               | Decision Tree, Logistic Regression, SVM, Naive Bayes, KNN                      |
| 2️⃣     | یادگیری انسمبل            | Ensemble Learning              | Random Forest, AdaBoost, Gradient Boosting, XGBoost, LightGBM, CatBoost        |
| 3️⃣     | یادگیری عمیق             | Deep Learning                  | MLP, CNN, RNN, LSTM, Autoencoder                                               |
| 4️⃣     | یادگیری ترکیبی           | Hybrid Learning                | ML + DL، Rule-Based + ML، Stacking، Blending                                   |
| 5️⃣     | مدل‌های گرافی             | Graph-Based Models             | GCN، GAT، GraphSAGE، Graph Attention Network، GATv2                            |
| 6️⃣     | کشف ناهنجاری             | Anomaly Detection              | Isolation Forest، One-Class SVM، LOF، Autoencoder (Unsupervised)              |
| 7️⃣     | یادگیری نیمه‌نظارتی       | Semi-Supervised Learning       | Label Propagation، Self-Training، Semi-Supervised SVM، Co-Training             |
| 8️⃣     | یادگیری تقویتی            | Reinforcement Learning         | Q-Learning، Deep Q-Network (DQN)، SARSA، Policy Gradient                      |
| 9️⃣     | یادگیری بدون نظارت        | Unsupervised Learning          | KMeans، DBSCAN، PCA، Autoencoder (Unsupervised)                               |

</div>

---

### ✳️ جدول موضوعات پایان‌نامه بر اساس دسته‌بندی روش‌های مدل‌سازی در کشف تقلب کارت‌های اعتباری 💳🧠📊

<div dir="rtl">

| 🔢 ردیف | 🎓📘 عنوان پیشنهادی پایان‌نامه (فارسی / English) |
|--------|---------------------------------------------------|
| 1️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از تکنیک‌های متعادل‌سازی داده و الگوریتم‌های یادگیری ماشین  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Data Balancing Techniques and Classical Machine Learning Algorithms* |
| 2️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های انسمبل و تکنیک‌های متعادل‌سازی داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Ensemble Models and Data Balancing Techniques* |
| 3️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از الگوریتم‌های یادگیری عمیق و رویکردهای مقابله با عدم‌توازن داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Deep Learning Algorithms and Imbalanced Data Handling Approaches* |
| 4️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های ترکیبی و تکنیک‌های متعادل‌سازی داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Hybrid Models and Data Balancing Techniques* |
| 5️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از مدل‌های مبتنی بر گراف و روش‌های مقابله با عدم‌توازن داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Graph-Based Models and Imbalanced Data Handling Techniques* |
| 6️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از روش‌های کشف ناهنجاری و تکنیک‌های متعادل‌سازی داده  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Anomaly Detection Methods and Data Balancing Techniques* |
| 7️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از یادگیری نیمه‌نظارتی و روش‌های مدیریت داده‌های نامتوازن  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Semi-Supervised Learning and Imbalanced Data Handling Techniques* |
| 8️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از یادگیری تقویتی و تکنیک‌های مقابله با داده‌های نامتوازن  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Reinforcement Learning and Imbalanced Data Handling Approaches* |
| 9️⃣ | 🎓 کشف تقلب در کارت‌های اعتباری با استفاده از الگوریتم‌های یادگیری بدون نظارت و تحلیل داده‌های نامتوازن  <br> 📘 *Credit Card Fraud Detection (CCFD) Using Unsupervised Learning Algorithms and Imbalanced Data Analysis* |


</div>


---


### ✔️ مسیر پیشنهادی نهایی برای پایان‌نامه:



### 🧠 مدل‌های انسمبل چیستند؟  
مدل‌های انسمبل مجموعه‌ای از الگوریتم‌های یادگیری ماشین هستند که به‌جای تکیه بر یک مدل واحد، چندین مدل پایه را ترکیب می‌کنند تا یک تصمیم نهایی دقیق‌تر، پایدارتر و قابل اعتمادتر ارائه دهند.  

ایده اصلی انسمبل این است که «ترکیب چند مدل ضعیف، می‌تواند منجر به یک مدل قوی‌تر شود» – درست مانند خرد جمعی.



### 💡 مزایای کلیدی انسمبل:

- **🎯 افزایش دقت:** با ترکیب چند مدل، خطاهای فردی کاهش می‌یابد.  
- **🛡️ کاهش overfitting:** به‌ویژه در داده‌های نامتوازن مثل CCFD بسیار مؤثر است.  
- **📊 پایداری بیشتر:** خروجی نهایی از چند زاویه بررسی می‌شود، نه فقط یک دیدگاه.  
- **🧪 انعطاف‌پذیری:** می‌توان مدل‌ها را از خانواده‌های مختلف ترکیب کرد (مثلاً Tree و Boost).



### 🎯 مدل‌های انسمبل زیرمجموعه کدام دسته‌اند؟  
### ⛓️ ساختار سلسله‌مراتبی:

هوش مصنوعی (AI)  
└── یادگیری ماشین (Machine Learning)  
&emsp;└── یادگیری نظارت‌شده (Supervised Learning)  
&emsp;&emsp;└── مدل‌های انسمبل (Ensemble Models)



### ✳️ چرا برای پایان‌نامه ما مناسب است؟  
در مسئله کشف تقلب در کارت‌های اعتباری، داده‌ها به‌شدت نامتوازن و حساس‌اند. انسمبل‌ها با قدرت ترکیب و تعمیم، می‌توانند خطاهای تشخیص را کاهش داده، دقت را بالا برده و راهکاری قوی‌تر از مدل‌های ساده ارائه کنند.


---


### 🧠 جدول یک‌ستونه معرفی انواع مدل‌های انسمبل

| 🎯 انواع مدل‌های انسمبل |
|--------------------------|
| ### 1️⃣ **Bagging (Bootstrap Aggregating)**  
روش Bagging یکی از تکنیک‌های انسمبل ساده و مؤثر در یادگیری ماشین است که هدف اصلی آن **کاهش واریانس و افزایش پایداری مدل** است. در این روش:

1. از دیتای اصلی، چندین **زیرمجموعه تصادفی با جایگزینی (Bootstrapped samples)** ساخته می‌شود.  
2. روی هر زیرمجموعه، **یک مدل مشابه از یک الگوریتم واحد** (مثلاً فقط درخت تصمیم) آموزش داده می‌شود.  
3. خروجی نهایی از طریق **رأی‌گیری اکثریت (برای طبقه‌بندی)** یا **میانگین‌گیری (برای رگرسیون)** به‌دست می‌آید.

### ✅ ویژگی‌های کلیدی:
- همه مدل‌ها از **یک الگوریتم مشخص** استفاده می‌کنند.  
- تنها تفاوت بین آن‌ها، **نمونه‌های آموزش متفاوت** است.  
- انتخاب داده‌ها در هر زیرمجموعه، کاملاً **تصادفی با جایگزینی** انجام می‌شود.  
- مدل نهایی با ترکیب خروجی‌ها، به **نتیجه‌ای دقیق‌تر، پایدارتر و مقاوم‌تر در برابر نویز** می‌رسد. |
| ### 2️⃣ **Boosting**  
روش Boosting یکی از تکنیک‌های قدرتمند انسمبل در یادگیری ماشین است که با هدف **کاهش بایاس و افزایش دقت مدل** طراحی شده است. در این روش:

1. مدل‌های پایه (معمولاً ضعیف) به‌صورت **ترتیبی و زنجیره‌ای** آموزش داده می‌شوند.  
2. هر مدل جدید، **روی خطاهای مدل قبلی تمرکز** می‌کند و تلاش می‌کند پیش‌بینی آن‌ها را اصلاح کند.  
3. خروجی نهایی با **ترکیب وزن‌دار پیش‌بینی‌های تمام مدل‌ها** به‌دست می‌آید.

### ✅ ویژگی‌های کلیدی:
- همه مدل‌ها از **یک الگوریتم یکسان** (مثلاً درخت تصمیم ساده) استفاده می‌کنند.  
- مدل‌ها به‌صورت **وابسته و مرحله‌ای** آموزش می‌بینند.  
- در هر مرحله، به **نمونه‌های اشتباه‌شده قبلی وزن بیشتری** داده می‌شود.  
- Boosting در مواجهه با **داده‌های نامتوازن و الگوهای پیچیده** عملکرد بسیار دقیقی دارد. |
| ### 3️⃣ **Stacking (Stacked Generalization)**  
Stacking یک تکنیک انسمبل پیشرفته در یادگیری ماشین است که با هدف افزایش دقت مدل نهایی، از **ویژگی‌سازی مبتنی بر خروجی چند مدل مختلف** استفاده می‌کند و آن‌ها را به یک **مدل نهایی هوشمند** می‌سپارد تا تصمیم‌گیری نهایی انجام شود.

1. چندین **مدل پایه (Base Learners)** با الگوریتم‌های متفاوت (مثل SVM، Random Forest، KNN) روی داده‌ی اصلی آموزش داده می‌شوند.  
2. خروجی‌های این مدل‌ها (پیش‌بینی یا احتمال) برای هر نمونه استخراج می‌گردد.  
3. این خروجی‌ها به‌عنوان **ویژگی‌های جدید** به یک **مدل نهایی (Meta Learner)** داده می‌شوند تا تصمیم نهایی را اتخاذ کند.

### ✅ ویژگی‌های کلیدی:
- استفاده از مدل‌های پایه با **الگوریتم‌های متنوع و مستقل**  
- مدل نهایی می‌تواند **هر الگوریتمی** باشد (معمولاً ساده، مثل Logistic Regression یا XGBoost)  
- مناسب برای مسائل پیچیده و **داده‌های نامتوازن**  
- عملکرد کلی معمولاً بهتر از هر یک از مدل‌ها به‌تنهایی است |
| ### 4️⃣ **Voting (Hard Voting / Soft Voting)**  
Voting یکی از روش‌های ساده و مؤثر انسمبل در یادگیری ماشین است که با ترکیب خروجی چند مدل مستقل، تصمیم نهایی را اتخاذ می‌کند. در این روش:

1. یک دیتاست مشخص، به چندین مدل یادگیری ماشین با **الگوریتم‌های متفاوت** داده می‌شود.  
2. هر مدل به‌صورت **مستقل و موازی** آموزش می‌بیند.  
3. در زمان پیش‌بینی، خروجی تمام مدل‌ها گرفته شده و **ترکیب می‌شود** تا نتیجه نهایی تولید شود.

### ✅ دو نوع اصلی Voting:
- **Hard Voting:** انتخاب کلاسی که **بیشترین رأی** را از بین مدل‌ها کسب کرده باشد  
- **Soft Voting:** انتخاب کلاسی که **بیشترین میانگین احتمال** را از بین مدل‌ها داشته باشد

### 🗳️ نوع تصمیم‌گیری:
- **Hard Voting** → اکثریت رأی‌ها (کدام کلاس بیشتر رأی آورده؟)  
- **Soft Voting** → میانگین احتمال‌ها (کدام کلاس احتمال بیشتری دارد؟)

### 🎯 ویژگی‌های کلیدی:
- استفاده از مدل‌های متنوع (مثل Random Forest، KNN، SVM و ...)  
- پیاده‌سازی آسان و مناسب برای شروع ترکیب مدل‌ها  
- کاهش خطای کلی سیستم با **پوشش ضعف هر مدل توسط مدل‌های دیگر**  
- Soft Voting معمولاً عملکرد دقیق‌تری نسبت به Hard Voting دارد |
